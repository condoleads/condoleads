// app/api/admin/psf-analytics/calculate/route.ts

import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { fetchSaleData, fetchLeaseData, fetchBuildingSaleData, fetchBuildingLeaseData } from '@/lib/psf/fetch-proptx';
import { processRecords, calculatePeriodMetrics, groupByGeography } from '@/lib/psf/calculate-psf';
import { getSqft } from '@/lib/psf/extraction';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const BATCH_SIZE = 10;

interface CalculateRequest {
  level: 'gta' | 'area' | 'areas' | 'municipality' | 'municipalities' | 'community' | 'communities' | 'building' | 'buildings';
  type: 'sale' | 'lease' | 'both';
  name?: string;
  maxRecords?: number;
}

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  const body: CalculateRequest = await request.json();
  const { level, type = 'both', name, maxRecords = 50000 } = body;

  const results = {
    level,
    type,
    name: name || 'all',
    sale: { processed: 0, geographies: 0, periods: 0 },
    lease: { processed: 0, geographies: 0, periods: 0 },
    errors: [] as string[],
    duration: 0,
  };

  // Create log entry
  const { data: logEntry } = await supabase
    .from('psf_calculation_log')
    .insert({
      calculation_type: type,
      geo_level: level,
      geo_name: name || 'all',
      status: 'running',
    })
    .select('id')
    .single();

  try {
    // SALE CALCULATIONS
    if (type === 'sale' || type === 'both') {
      const saleResults = await calculateForType('sale', level, name, maxRecords);
      results.sale = saleResults;
      results.errors.push(...saleResults.errors);
    }

    // LEASE CALCULATIONS
    if (type === 'lease' || type === 'both') {
      const leaseResults = await calculateForType('lease', level, name, maxRecords);
      results.lease = leaseResults;
      results.errors.push(...leaseResults.errors);
    }

    results.duration = Math.round((Date.now() - startTime) / 1000);

    // Update log entry
    if (logEntry?.id) {
      await supabase
        .from('psf_calculation_log')
        .update({
          status: 'completed',
          completed_at: new Date().toISOString(),
          sale_records_processed: results.sale.processed,
          lease_records_processed: results.lease.processed,
          geographies_updated: results.sale.geographies + results.lease.geographies,
          months_processed: results.sale.periods + results.lease.periods,
          errors: results.errors.length > 0 ? results.errors : null,
          duration_seconds: results.duration,
        })
        .eq('id', logEntry.id);
    }

    return NextResponse.json({ success: true, ...results });
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : 'Unknown error';
    results.errors.push(errorMsg);

    if (logEntry?.id) {
      await supabase
        .from('psf_calculation_log')
        .update({
          status: 'failed',
          completed_at: new Date().toISOString(),
          errors: results.errors,
          duration_seconds: Math.round((Date.now() - startTime) / 1000),
        })
        .eq('id', logEntry.id);
    }

    return NextResponse.json({ success: false, ...results }, { status: 500 });
  }
}

async function calculateForType(
  type: 'sale' | 'lease',
  level: string,
  name: string | undefined,
  maxRecords: number
) {
  const results = { processed: 0, geographies: 0, periods: 0, errors: [] as string[] };
  const tableName = type === 'sale' ? 'psf_monthly_sale' : 'psf_monthly_lease';
  const fetchFn = type === 'sale' ? fetchSaleData : fetchLeaseData;

  console.log(`[PSF] Starting ${type} calculation for ${level}: ${name || 'all'}`);

  // Handle different levels
  if (level === 'gta') {
    const { records } = await fetchFn(undefined, undefined, maxRecords);
    results.processed = records.length;
    
    const processed = processRecords(records);
    const periodMetrics = calculatePeriodMetrics(processed);
    
    for (const metrics of periodMetrics) {
      await savePeriodMetrics(tableName, 'gta', null, null, metrics);
      results.periods++;
    }
    results.geographies = 1;
  }
  else if (level === 'area' || level === 'areas') {
    const { data: areas } = await supabase.from('treb_areas').select('id, name');
    
    if (name) {
      const area = areas?.find(a => a.name === name);
      if (area) {
        await processGeography(type, 'area', 'CountyOrParish', area.name, area.id, tableName, fetchFn, maxRecords, results);
      }
    } else {
      for (let i = 0; i < (areas?.length || 0); i += BATCH_SIZE) {
        const batch = areas!.slice(i, i + BATCH_SIZE);
        await Promise.all(
          batch.map(area => 
            processGeography(type, 'area', 'CountyOrParish', area.name, area.id, tableName, fetchFn, maxRecords, results)
          )
        );
        console.log(`[PSF ${type}] Areas: ${Math.min(i + BATCH_SIZE, areas!.length)}/${areas!.length}`);
      }
    }
  }
  else if (level === 'municipality' || level === 'municipalities') {
    const { data: munis } = await supabase.from('municipalities').select('id, name');
    
    if (name) {
      const muni = munis?.find(m => m.name === name);
      if (muni) {
        await processGeography(type, 'municipality', 'City', muni.name, muni.id, tableName, fetchFn, maxRecords, results);
      }
    } else {
      for (let i = 0; i < (munis?.length || 0); i += BATCH_SIZE) {
        const batch = munis!.slice(i, i + BATCH_SIZE);
        await Promise.all(
          batch.map(muni => 
            processGeography(type, 'municipality', 'City', muni.name, muni.id, tableName, fetchFn, maxRecords, results)
          )
        );
        console.log(`[PSF ${type}] Municipalities: ${Math.min(i + BATCH_SIZE, munis!.length)}/${munis!.length}`);
      }
    }
  }
  else if (level === 'community' || level === 'communities') {
    const { data: comms } = await supabase.from('communities').select('id, name');
    
    if (name) {
      const comm = comms?.find(c => c.name === name);
      if (comm) {
        await processGeography(type, 'community', 'CityRegion', comm.name, comm.id, tableName, fetchFn, maxRecords, results);
      }
    } else {
      for (let i = 0; i < (comms?.length || 0); i += BATCH_SIZE) {
        const batch = comms!.slice(i, i + BATCH_SIZE);
        await Promise.all(
          batch.map(comm => 
            processGeography(type, 'community', 'CityRegion', comm.name, comm.id, tableName, fetchFn, maxRecords, results)
          )
        );
        console.log(`[PSF ${type}] Communities: ${Math.min(i + BATCH_SIZE, comms!.length)}/${comms!.length}`);
      }
    }
  }
 else if (level === 'building' || level === 'buildings') {
    // NEW BUILDING LOGIC: Save individual transactions + calculate summary
    const { data: buildings } = await supabase
      .from('buildings')
      .select(`
        id,
        building_name,
        street_number,
        street_name,
        city_district,
        community_id
      `)
      .not('community_id', 'is', null)
      .not('street_number', 'is', null)
      .not('street_name', 'is', null)
      .not('city_district', 'is', null);

    if (!buildings || buildings.length === 0) {
      console.log('[PSF] No buildings with complete data found');
      return results;
    }

    console.log(`[PSF ${type}] Processing ${buildings.length} buildings (individual transactions)`);

    const buildingFetchFn = type === 'sale' ? fetchBuildingSaleData : fetchBuildingLeaseData;

    for (let i = 0; i < buildings.length; i += BATCH_SIZE) {
      const batch = buildings.slice(i, i + BATCH_SIZE);

      await Promise.all(batch.map(async (building: any) => {
        try {
          const { records } = await buildingFetchFn(
            building.street_number,
            building.street_name,
            building.city_district
          );

          if (records.length === 0) return;

          results.processed += records.length;

          // Save individual transactions
          const transactions: any[] = [];
          for (const record of records) {
            if (!record.ClosePrice || !record.CloseDate) continue;

            const sqftResult = getSqft(record.SquareFootSource, record.LivingAreaRange);
            const psf = record.ClosePrice / sqftResult.sqft;

            transactions.push({
              building_id: building.id,
              transaction_type: type,
              close_date: record.CloseDate.split('T')[0],
              close_price: record.ClosePrice,
              sqft: sqftResult.sqft,
              sqft_method: sqftResult.method,
              psf: Math.round(psf * 100) / 100,
              has_parking: (record.ParkingTotal || 0) > 0,
              parking_spaces: record.ParkingTotal || 0,
              living_area_range: record.LivingAreaRange,
              calculated_at: new Date().toISOString(),
            });
          }

          // Upsert transactions (unique on building_id, transaction_type, close_date, close_price, sqft)
          if (transactions.length > 0) {
            const { error: txError } = await supabase
              .from('building_psf_transactions')
              .upsert(transactions, {
                onConflict: 'building_id,transaction_type,close_date,close_price,sqft',
                ignoreDuplicates: false
              });

            if (txError) {
              console.error(`[PSF] Transaction save error for ${building.building_name}:`, txError.message);
            }

            // Calculate and save summary
            await saveBuildingSummary(building.id, type, transactions);
            results.periods += transactions.length;
          }

          results.geographies++;
        } catch (error) {
          const errMsg = `Building ${building.building_name}: ${error instanceof Error ? error.message : 'Unknown'}`;
          results.errors.push(errMsg);
          console.error('[PSF] Building error:', errMsg);
        }
      }));

      console.log(`[PSF ${type}] Buildings: ${Math.min(i + BATCH_SIZE, buildings.length)}/${buildings.length}`);
    }
  }

  return results;
}

async function processGeography(
  type: 'sale' | 'lease',
  geoLevel: 'area' | 'municipality' | 'community',
  proptxField: 'CountyOrParish' | 'City' | 'CityRegion',
  geoName: string,
  geoId: string,
  tableName: string,
  fetchFn: typeof fetchSaleData,
  maxRecords: number,
  results: { processed: number; geographies: number; periods: number; errors: string[] }
) {
  try {
    const { records } = await fetchFn(proptxField, geoName, maxRecords);
    results.processed += records.length;

    if (records.length === 0) return;

    const processed = processRecords(records);
    const periodMetrics = calculatePeriodMetrics(processed);

    for (const metrics of periodMetrics) {
      await savePeriodMetrics(tableName, geoLevel, geoId, null, metrics);
      results.periods++;
    }

    results.geographies++;
  } catch (error) {
    const errorMsg = `${geoLevel} ${geoName}: ${error instanceof Error ? error.message : 'Unknown error'}`;
    results.errors.push(errorMsg);
    console.error(`[PSF] Error:`, errorMsg);
  }
}

async function savePeriodMetrics(
  tableName: string,
  geoLevel: string,
  geoId: string | null,
  buildingAddress: string | null,
  metrics: ReturnType<typeof calculatePeriodMetrics>[0]
) {
  const record: Record<string, any> = {
    geo_level: geoLevel,
    period_year: metrics.year,
    period_month: metrics.month,
    period_start: metrics.periodStart.toISOString().split('T')[0],
    period_end: metrics.periodEnd.toISOString().split('T')[0],
    
    all_avg_psf: metrics.all.avgPsf,
    all_median_psf: metrics.all.medianPsf,
    all_min_psf: metrics.all.minPsf,
    all_max_psf: metrics.all.maxPsf,
    all_stddev_psf: metrics.all.stddevPsf,
    all_sample_size: metrics.all.sampleSize,
    all_total_value: metrics.all.totalValue,
    all_total_sqft: metrics.all.totalSqft,
    
    parking_avg_psf: metrics.withParking.avgPsf,
    parking_median_psf: metrics.withParking.medianPsf,
    parking_sample_size: metrics.withParking.sampleSize,
    parking_total_value: metrics.withParking.totalValue,
    parking_total_sqft: metrics.withParking.totalSqft,
    
    no_parking_avg_psf: metrics.withoutParking.avgPsf,
    no_parking_median_psf: metrics.withoutParking.medianPsf,
    no_parking_sample_size: metrics.withoutParking.sampleSize,
    no_parking_total_value: metrics.withoutParking.totalValue,
    no_parking_total_sqft: metrics.withoutParking.totalSqft,
    
    parking_premium_psf: metrics.parkingPremiumPsf,
    parking_premium_pct: metrics.parkingPremiumPct,
    
    exact_sqft_count: metrics.exactCount,
    midpoint_sqft_count: metrics.midpointCount,
    fallback_sqft_count: metrics.fallbackCount,
    
    calculated_at: new Date().toISOString(),
  };

  // Set geography IDs based on level
  if (geoLevel === 'area' && geoId) {
    record.area_id = geoId;
  } else if (geoLevel === 'municipality' && geoId) {
    record.municipality_id = geoId;
  } else if (geoLevel === 'community' && geoId) {
    record.community_id = geoId;
  } else if (geoLevel === 'building' && buildingAddress) {
    record.building_address = buildingAddress;
  }

  // Insert record
  console.log('[PSF] Attempting insert to:', tableName, 'geo_level:', record.geo_level, 'period:', record.period_year + '-' + record.period_month);
  const { data, error } = await supabase
    .from(tableName)
    .upsert(record, { 
      onConflict: 'geo_level,area_id,municipality_id,community_id,building_id,building_address,period_year,period_month',
      ignoreDuplicates: false 
    })
    .select();
  
  console.log('[PSF] Insert result - data:', data?.length, 'error:', error?.message);

  if (error) {
    console.error(`[PSF] Save error:`, error.message);
  }
}

async function saveBuildingMetrics(
  tableName: string,
  buildingId: string,
  communityId: string,
  municipalityId: string,
  areaId: string,
  metrics: ReturnType<typeof calculatePeriodMetrics>[0]
) {
  const record: Record<string, any> = {
    geo_level: 'building',
    building_id: buildingId,
    community_id: communityId,
    municipality_id: municipalityId,
    area_id: areaId,
    period_year: metrics.year,
    period_month: metrics.month,
    period_start: metrics.periodStart.toISOString().split('T')[0],
    period_end: metrics.periodEnd.toISOString().split('T')[0],
    
    all_avg_psf: metrics.all.avgPsf,
    all_median_psf: metrics.all.medianPsf,
    all_min_psf: metrics.all.minPsf,
    all_max_psf: metrics.all.maxPsf,
    all_stddev_psf: metrics.all.stddevPsf,
    all_sample_size: metrics.all.sampleSize,
    all_total_value: metrics.all.totalValue,
    all_total_sqft: metrics.all.totalSqft,
    
    parking_avg_psf: metrics.withParking.avgPsf,
    parking_median_psf: metrics.withParking.medianPsf,
    parking_sample_size: metrics.withParking.sampleSize,
    parking_total_value: metrics.withParking.totalValue,
    parking_total_sqft: metrics.withParking.totalSqft,
    
    no_parking_avg_psf: metrics.withoutParking.avgPsf,
    no_parking_median_psf: metrics.withoutParking.medianPsf,
    no_parking_sample_size: metrics.withoutParking.sampleSize,
    no_parking_total_value: metrics.withoutParking.totalValue,
    no_parking_total_sqft: metrics.withoutParking.totalSqft,
    
    parking_premium_psf: metrics.parkingPremiumPsf,
    parking_premium_pct: metrics.parkingPremiumPct,
    exact_sqft_count: metrics.exactCount,
    midpoint_sqft_count: metrics.midpointCount,
    fallback_sqft_count: metrics.fallbackCount,
    calculated_at: new Date().toISOString(),
  };

  console.log('[PSF] Saving building metrics:', buildingId, 'period:', metrics.year + '-' + metrics.month);
  
  const { data, error } = await supabase
    .from(tableName)
    .upsert(record, { 
      onConflict: 'geo_level,area_id,municipality_id,community_id,building_id,building_address,period_year,period_month',
      ignoreDuplicates: false 
    })
    .select();

  if (error) {
    console.error('[PSF] Building save error:', error.message);
  }
}

async function saveBuildingSummary(
  buildingId: string,
  type: 'sale' | 'lease',
  transactions: any[]
) {
  if (transactions.length === 0) return;

  const psfValues = transactions.map(t => t.psf).sort((a: number, b: number) => a - b);
  const totalValue = transactions.reduce((sum: number, t: any) => sum + t.close_price, 0);
  const totalSqft = transactions.reduce((sum: number, t: any) => sum + t.sqft, 0);

  const avgPsf = totalSqft > 0 ? Math.round((totalValue / totalSqft) * 100) / 100 : null;
  const medianPsf = psfValues.length > 0 ? Math.round(psfValues[Math.floor(psfValues.length / 2)] * 100) / 100 : null;
  const minPsf = psfValues.length > 0 ? Math.round(psfValues[0] * 100) / 100 : null;
  const maxPsf = psfValues.length > 0 ? Math.round(psfValues[psfValues.length - 1] * 100) / 100 : null;

  const exactCount = transactions.filter((t: any) => t.sqft_method === 'exact').length;
  const midpointCount = transactions.filter((t: any) => t.sqft_method === 'midpoint').length;
  const fallbackCount = transactions.filter((t: any) => t.sqft_method === 'fallback').length;

  const dates = transactions.map((t: any) => t.close_date).sort();
  const earliest = dates[0];
  const latest = dates[dates.length - 1];

  // Build update object based on type
  const prefix = type === 'sale' ? 'sale' : 'lease';
  const updateData: Record<string, any> = {
    building_id: buildingId,
    [`${prefix}_avg_psf`]: avgPsf,
    [`${prefix}_median_psf`]: medianPsf,
    [`${prefix}_min_psf`]: minPsf,
    [`${prefix}_max_psf`]: maxPsf,
    [`${prefix}_count`]: transactions.length,
    [`${prefix}_exact_count`]: exactCount,
    [`${prefix}_midpoint_count`]: midpointCount,
    [`${prefix}_fallback_count`]: fallbackCount,
    earliest_transaction: earliest,
    latest_transaction: latest,
    calculated_at: new Date().toISOString(),
  };

  const { error } = await supabase
    .from('building_psf_summary')
    .upsert(updateData, {
      onConflict: 'building_id',
      ignoreDuplicates: false
    });

  if (error) {
    console.error(`[PSF] Summary save error for building ${buildingId}:`, error.message);
  }
}

export async function GET() {
  // Return recent calculation logs
  const { data: logs } = await supabase
    .from('psf_calculation_log')
    .select('*')
    .order('started_at', { ascending: false })
    .limit(20);

  return NextResponse.json({ logs });
}




