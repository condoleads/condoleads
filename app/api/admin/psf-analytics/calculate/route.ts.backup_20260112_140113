// app/api/admin/psf-analytics/calculate/route.ts

import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { fetchSaleData, fetchLeaseData } from '@/lib/psf/fetch-proptx';
import { processRecords, calculatePeriodMetrics, groupByGeography } from '@/lib/psf/calculate-psf';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const BATCH_SIZE = 10;

interface CalculateRequest {
  level: 'gta' | 'area' | 'areas' | 'municipality' | 'municipalities' | 'community' | 'communities' | 'building' | 'buildings';
  type: 'sale' | 'lease' | 'both';
  name?: string;
  maxRecords?: number;
}

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  const body: CalculateRequest = await request.json();
  const { level, type = 'both', name, maxRecords = 50000 } = body;

  const results = {
    level,
    type,
    name: name || 'all',
    sale: { processed: 0, geographies: 0, periods: 0 },
    lease: { processed: 0, geographies: 0, periods: 0 },
    errors: [] as string[],
    duration: 0,
  };

  // Create log entry
  const { data: logEntry } = await supabase
    .from('psf_calculation_log')
    .insert({
      calculation_type: type,
      geo_level: level,
      geo_name: name || 'all',
      status: 'running',
    })
    .select('id')
    .single();

  try {
    // SALE CALCULATIONS
    if (type === 'sale' || type === 'both') {
      const saleResults = await calculateForType('sale', level, name, maxRecords);
      results.sale = saleResults;
      results.errors.push(...saleResults.errors);
    }

    // LEASE CALCULATIONS
    if (type === 'lease' || type === 'both') {
      const leaseResults = await calculateForType('lease', level, name, maxRecords);
      results.lease = leaseResults;
      results.errors.push(...leaseResults.errors);
    }

    results.duration = Math.round((Date.now() - startTime) / 1000);

    // Update log entry
    if (logEntry?.id) {
      await supabase
        .from('psf_calculation_log')
        .update({
          status: 'completed',
          completed_at: new Date().toISOString(),
          sale_records_processed: results.sale.processed,
          lease_records_processed: results.lease.processed,
          geographies_updated: results.sale.geographies + results.lease.geographies,
          months_processed: results.sale.periods + results.lease.periods,
          errors: results.errors.length > 0 ? results.errors : null,
          duration_seconds: results.duration,
        })
        .eq('id', logEntry.id);
    }

    return NextResponse.json({ success: true, ...results });
  } catch (error) {
    const errorMsg = error instanceof Error ? error.message : 'Unknown error';
    results.errors.push(errorMsg);

    if (logEntry?.id) {
      await supabase
        .from('psf_calculation_log')
        .update({
          status: 'failed',
          completed_at: new Date().toISOString(),
          errors: results.errors,
          duration_seconds: Math.round((Date.now() - startTime) / 1000),
        })
        .eq('id', logEntry.id);
    }

    return NextResponse.json({ success: false, ...results }, { status: 500 });
  }
}

async function calculateForType(
  type: 'sale' | 'lease',
  level: string,
  name: string | undefined,
  maxRecords: number
) {
  const results = { processed: 0, geographies: 0, periods: 0, errors: [] as string[] };
  const tableName = type === 'sale' ? 'psf_monthly_sale' : 'psf_monthly_lease';
  const fetchFn = type === 'sale' ? fetchSaleData : fetchLeaseData;

  console.log(`[PSF] Starting ${type} calculation for ${level}: ${name || 'all'}`);

  // Handle different levels
  if (level === 'gta') {
    const { records } = await fetchFn(undefined, undefined, maxRecords);
    results.processed = records.length;
    
    const processed = processRecords(records);
    const periodMetrics = calculatePeriodMetrics(processed);
    
    for (const metrics of periodMetrics) {
      await savePeriodMetrics(tableName, 'gta', null, null, metrics);
      results.periods++;
    }
    results.geographies = 1;
  }
  else if (level === 'area' || level === 'areas') {
    const { data: areas } = await supabase.from('treb_areas').select('id, name');
    
    if (name) {
      const area = areas?.find(a => a.name === name);
      if (area) {
        await processGeography(type, 'area', 'CountyOrParish', area.name, area.id, tableName, fetchFn, maxRecords, results);
      }
    } else {
      for (let i = 0; i < (areas?.length || 0); i += BATCH_SIZE) {
        const batch = areas!.slice(i, i + BATCH_SIZE);
        await Promise.all(
          batch.map(area => 
            processGeography(type, 'area', 'CountyOrParish', area.name, area.id, tableName, fetchFn, maxRecords, results)
          )
        );
        console.log(`[PSF ${type}] Areas: ${Math.min(i + BATCH_SIZE, areas!.length)}/${areas!.length}`);
      }
    }
  }
  else if (level === 'municipality' || level === 'municipalities') {
    const { data: munis } = await supabase.from('municipalities').select('id, name');
    
    if (name) {
      const muni = munis?.find(m => m.name === name);
      if (muni) {
        await processGeography(type, 'municipality', 'City', muni.name, muni.id, tableName, fetchFn, maxRecords, results);
      }
    } else {
      for (let i = 0; i < (munis?.length || 0); i += BATCH_SIZE) {
        const batch = munis!.slice(i, i + BATCH_SIZE);
        await Promise.all(
          batch.map(muni => 
            processGeography(type, 'municipality', 'City', muni.name, muni.id, tableName, fetchFn, maxRecords, results)
          )
        );
        console.log(`[PSF ${type}] Municipalities: ${Math.min(i + BATCH_SIZE, munis!.length)}/${munis!.length}`);
      }
    }
  }
  else if (level === 'community' || level === 'communities') {
    const { data: comms } = await supabase.from('communities').select('id, name');
    
    if (name) {
      const comm = comms?.find(c => c.name === name);
      if (comm) {
        await processGeography(type, 'community', 'CityRegion', comm.name, comm.id, tableName, fetchFn, maxRecords, results);
      }
    } else {
      for (let i = 0; i < (comms?.length || 0); i += BATCH_SIZE) {
        const batch = comms!.slice(i, i + BATCH_SIZE);
        await Promise.all(
          batch.map(comm => 
            processGeography(type, 'community', 'CityRegion', comm.name, comm.id, tableName, fetchFn, maxRecords, results)
          )
        );
        console.log(`[PSF ${type}] Communities: ${Math.min(i + BATCH_SIZE, comms!.length)}/${comms!.length}`);
      }
    }
  }
  else if (level === 'building' || level === 'buildings') {
    // For buildings, we fetch all data and group in memory
    const { records } = await fetchFn(undefined, undefined, maxRecords);
    results.processed = records.length;
    
    const processed = processRecords(records);
    const byBuilding = groupByGeography(processed, 'building');
    
    let buildingCount = 0;
    for (const [buildingKey, buildingRecords] of byBuilding) {
      if (buildingRecords.length < 3) continue; // Skip buildings with too few records
      
      const periodMetrics = calculatePeriodMetrics(buildingRecords);
      
      for (const metrics of periodMetrics) {
        await savePeriodMetrics(tableName, 'building', null, buildingKey, metrics);
        results.periods++;
      }
      
      buildingCount++;
      if (buildingCount % 100 === 0) {
        console.log(`[PSF ${type}] Buildings: ${buildingCount}/${byBuilding.size}`);
      }
    }
    results.geographies = buildingCount;
  }

  return results;
}

async function processGeography(
  type: 'sale' | 'lease',
  geoLevel: 'area' | 'municipality' | 'community',
  proptxField: 'CountyOrParish' | 'City' | 'CityRegion',
  geoName: string,
  geoId: string,
  tableName: string,
  fetchFn: typeof fetchSaleData,
  maxRecords: number,
  results: { processed: number; geographies: number; periods: number; errors: string[] }
) {
  try {
    const { records } = await fetchFn(proptxField, geoName, maxRecords);
    results.processed += records.length;

    if (records.length === 0) return;

    const processed = processRecords(records);
    const periodMetrics = calculatePeriodMetrics(processed);

    for (const metrics of periodMetrics) {
      await savePeriodMetrics(tableName, geoLevel, geoId, null, metrics);
      results.periods++;
    }

    results.geographies++;
  } catch (error) {
    const errorMsg = `${geoLevel} ${geoName}: ${error instanceof Error ? error.message : 'Unknown error'}`;
    results.errors.push(errorMsg);
    console.error(`[PSF] Error:`, errorMsg);
  }
}

async function savePeriodMetrics(
  tableName: string,
  geoLevel: string,
  geoId: string | null,
  buildingAddress: string | null,
  metrics: ReturnType<typeof calculatePeriodMetrics>[0]
) {
  const record: Record<string, any> = {
    geo_level: geoLevel,
    period_year: metrics.year,
    period_month: metrics.month,
    period_start: metrics.periodStart.toISOString().split('T')[0],
    period_end: metrics.periodEnd.toISOString().split('T')[0],
    
    all_avg_psf: metrics.all.avgPsf,
    all_median_psf: metrics.all.medianPsf,
    all_min_psf: metrics.all.minPsf,
    all_max_psf: metrics.all.maxPsf,
    all_stddev_psf: metrics.all.stddevPsf,
    all_sample_size: metrics.all.sampleSize,
    all_total_value: metrics.all.totalValue,
    all_total_sqft: metrics.all.totalSqft,
    
    parking_avg_psf: metrics.withParking.avgPsf,
    parking_median_psf: metrics.withParking.medianPsf,
    parking_sample_size: metrics.withParking.sampleSize,
    parking_total_value: metrics.withParking.totalValue,
    parking_total_sqft: metrics.withParking.totalSqft,
    
    no_parking_avg_psf: metrics.withoutParking.avgPsf,
    no_parking_median_psf: metrics.withoutParking.medianPsf,
    no_parking_sample_size: metrics.withoutParking.sampleSize,
    no_parking_total_value: metrics.withoutParking.totalValue,
    no_parking_total_sqft: metrics.withoutParking.totalSqft,
    
    parking_premium_psf: metrics.parkingPremiumPsf,
    parking_premium_pct: metrics.parkingPremiumPct,
    
    exact_sqft_count: metrics.exactCount,
    midpoint_sqft_count: metrics.midpointCount,
    fallback_sqft_count: metrics.fallbackCount,
    
    calculated_at: new Date().toISOString(),
  };

  // Set geography IDs based on level
  if (geoLevel === 'area' && geoId) {
    record.area_id = geoId;
  } else if (geoLevel === 'municipality' && geoId) {
    record.municipality_id = geoId;
  } else if (geoLevel === 'community' && geoId) {
    record.community_id = geoId;
  } else if (geoLevel === 'building' && buildingAddress) {
    record.building_address = buildingAddress;
  }

  // Upsert to handle duplicates
  const { error } = await supabase
    .from(tableName)
    .upsert(record, {
      onConflict: 'geo_level,area_id,municipality_id,community_id,building_id,building_address,period_year,period_month',
    });

  if (error) {
    console.error(`[PSF] Save error:`, error.message);
  }
}

export async function GET() {
  // Return recent calculation logs
  const { data: logs } = await supabase
    .from('psf_calculation_log')
    .select('*')
    .order('started_at', { ascending: false })
    .limit(20);

  return NextResponse.json({ logs });
}
